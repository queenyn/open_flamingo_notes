# ResNet 学习总结

## 为什么需要 ResNet

传统深层神经网络随着层数增加，训练时常遇到梯度消失和梯度爆炸，导致性能下降（退化问题）。ResNet 的设计正是建立在“恒等映射”的基础上，通过引入残差学习，有效缓解训练难题，使得更深层网络可以稳定训练并提升性能。

## ResNet 的结构

ResNet 的核心是“残差块”，通过跳跃连接将输入 \(x\) 与残差函数 \(F(x)\) 相加，形成输出 \(y = F(x) + x\)。  
- 结构一般包含两到三层卷积，配合 Batch Normalization 和 ReLU。  
- 当输入输出维度不匹配时，使用 1x1 卷积调整输入维度，使相加维度一致。  
- 跳跃连接实现恒等映射，保证梯度顺畅传播。

## ResNet 如何解决问题

1. **残差学习**：通过学习残差函数 \(F(x) = H(x) - x\)，将学习目标转化为“输入与输出的差异”，降低了学习难度。  
2. **恒等映射的跳跃连接**：确保信息和梯度能直接传递，缓解梯度消失和梯度爆炸问题。
3. **保底机制**：即使F（X）的学习出了问题，最差也就是令F（X）=0，退化回恒等映射。

## ResNet 的作用

1. 确保网络即使残差学习失败，也能退化为恒等映射，保证性能不下降。  
2. 使超深层网络训练成为可能，提升模型表达力和泛化能力。  
3. 推动计算机视觉等领域的技术进步。
